## 2.5 局部搜索（Local Search）

作为最后一个值得关注的主题，**回溯搜索**并不是求解约束满足问题的唯一算法。另一类被广泛使用的方法是**局部搜索（local search）**。其思想虽然看起来十分朴素，但却异常有效。局部搜索通过**迭代改进（iterative improvement）**来工作——从一个随机的赋值开始，然后反复执行以下过程：随机选择一个存在冲突的变量，并将其取值重新赋为**违反约束数量最少**的那个取值，直到不存在任何约束冲突为止（这一策略被称为**最小冲突启发式（min-conflicts heuristic）**）。在该策略下，像 $N$ 皇后这样的约束满足问题可以在时间和空间上都非常高效地求解。例如，在下面这个包含 4 个皇后的示例中，我们只经过 2 次迭代就得到了一个解：

![](../../image/2.CSPs/four-queens.png)

*Four queens*

事实上，局部搜索不仅在任意规模的 $N$ 皇后问题上看起来几乎可以在**常数时间**内运行，并且具有很高的成功概率，而且对任意**随机生成的 CSP** 也表现得非常有效！然而，尽管具备这些优点，局部搜索既是**不完备的（incomplete）**，也是**非最优的（suboptimal）**，因此并不能保证一定收敛到一个最优解。此外，还存在一个**临界比率（critical ratio）**，在该附近使用局部搜索会变得极其昂贵：

![](../../image/2.CSPs/critical-ratio.png)

*Critical ratio*

上图展示了状态空间中某个目标函数的一维示意图。对于该函数，我们希望找到对应**目标值最大的状态**。局部搜索算法的基本思想是：从当前状态出发，局部地朝向目标值更高的状态移动，直到到达某个极值点（理想情况下是全局最优解）。

![](../../image/2.CSPs/maxima_global_local.png)

*Global and local maxima*

我们将介绍三种这样的算法：**爬山法（hill-climbing）**、**模拟退火（simulated annealing）**以及**遗传算法（genetic algorithms）**。这些算法同样被广泛用于优化任务中，用以最大化或最小化某个目标函数。

## 2.5.1 爬山搜索（Hill-Climbing Search）

**爬山搜索算法**（也称为**最陡上升法，steepest-ascent**）从当前状态出发，移动到一个能够提升目标函数值的相邻状态。该算法不维护搜索树，而只保留当前状态及其对应的目标函数值。由于爬山算法的这种“贪心性”，它很容易陷入**局部极大值**（如下图所示），因为在这些点的局部看来，它们对算法而言就像是全局最大值一样。此外，算法还可能遇到**平台（plateaux）**问题。平台可以进一步分为两类：一类是不存在任何提升方向的“平坦局部极大值”，另一类是可以继续前进但进展十分缓慢的平坦区域（称为“肩部，shoulders”）。针对这些问题，人们提出了一些爬山法的变体，例如**随机爬山法（stochastic hill-climbing）**，它在所有上升方向中随机选择一个动作。实践表明，该方法往往能够以更多迭代为代价，收敛到更高的极值点。

![](../../image/2.CSPs/hill_climb-1.png)

*Hill climbing*

上图给出了爬山搜索的伪代码。顾名思义，该算法会不断迭代地移动到目标函数值更高的状态，直到再也无法取得改进为止。爬山搜索是**不完备的**。而**随机重启爬山法（Random-Restart hill-climbing）**则会从多个随机选择的初始状态出发，多次执行爬山搜索。由于在某一次重启中，初始状态终将与全局最优解重合，因此该方法在理论上是**完备的**。

## 2.5.2 模拟退火搜索（Simulated Annealing Search）

我们介绍的第二种局部搜索算法是**模拟退火**。模拟退火的目标是将**随机游走**（随机移动到相邻状态）与**爬山搜索**结合起来，从而获得一种既高效又完备的搜索算法。在模拟退火中，我们允许算法移动到那些**会降低目标函数值**的状态。更具体地说，在每一个状态下，算法都会随机选择一个移动。如果该移动使目标值增加，则一定接受该移动；如果该移动使目标值降低，则以某个概率接受该移动。该概率由一个称为**温度（temperature）**的参数决定，该参数在初始阶段较高（允许更多“坏”的移动），并按照某种时间表逐渐降低。如果温度下降得足够缓慢，那么模拟退火算法将以概率趋近于 1 的方式到达全局最优解。

![](../../image/2.CSPs/sim_ann-1.png)

*Simulated annealing*

## 2.5.3 遗传算法（Genetic Algorithms）

最后，我们介绍**遗传算法**。遗传算法是一种**局部束搜索（local beam search）**的变体，也被广泛应用于各种优化任务中。遗传算法以包含 $k$ 个随机初始化状态的束搜索开始，这些状态被称为**种群（population）**。状态（或个体）通常表示为某个有限字母表上的字符串。为了更好地理解这一思想，我们重新回顾课堂中介绍的 **8 皇后问题**。在 8 皇后问题中，我们可以用一个从 1 到 8 的数字来表示每一个皇后在对应列中的行位置（如图 4.6 中的列 (a) 所示）。每一个个体都会通过一个**评价函数（适应度函数，fitness function）**进行评估，并根据该函数值进行排序。对于 8 皇后问题，该适应度函数即为**不互相攻击的皇后对数目**。

![](../../image/2.CSPs/gen2-1.png)

*Genetic algorithm example*

选择某个状态用于“繁殖”的概率与该状态的评价值成正比。随后，我们根据这些概率选择状态对进行繁殖（如图 4.6 中的列 (c) 所示）。子代通过在父代字符串的某个**交叉点（crossover point）**进行交叉而生成，该交叉点对每一对父代都是随机选择的。最后，每一个子代都会以某个独立概率发生**随机变异（mutation）**。遗传算法的伪代码如下图所示：

![](../../image/2.CSPs/genetic-1.png)

*Genetic algorithm pseudocode*

遗传算法在探索状态空间并在不同“线程”之间交换信息的同时，试图整体上向更优解方向推进。其主要优势在于**交叉操作**：交叉使得那些已经进化出较高评价值的大块“基因片段”能够与其他类似片段相结合，从而生成一个整体得分很高的解。
