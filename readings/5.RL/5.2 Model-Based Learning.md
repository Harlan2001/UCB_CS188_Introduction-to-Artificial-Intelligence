## 5.2 基于模型的学习（Model-Based Learning）

在基于模型的学习中，智能体通过记录每次进入每个 Q-状态 `(s, a)` 后到达每个状态 `s'` 的次数，生成转移函数的近似：

\[
\hat{T}(s, a, s')
\]

然后，智能体可以在需要时生成近似转移函数 \(\hat{T}\)，方法是对收集到的计数进行归一化——将每个观测到的三元组 \((s, a, s')\) 的计数除以智能体在 Q-状态 \((s, a)\) 中的总计数。归一化后，所有概率之和为 1，可将其解释为概率。

### 示例 MDP

考虑以下 MDP，状态集合为：

\[
S = \{A, B, C, D, E, x\}
\]

其中 \(x\) 为终止状态，折扣因子 \(\gamma = 1\)。

![](../../image/5.RL/rl-example-1.png)

假设我们允许智能体在策略 \(\pi_{\text{explore}}\) 下探索该 MDP 四个回合（Directional triangle 表示方向移动，蓝色方块表示选择 exit 动作），得到以下结果：

![](../../image/5.RL/example-1-episodes.png)

---

### 示例回合（Example Episodes）

我们收集了总共 12 个样本，每回合 3 个样本，计数如下表：

| s | a | s' | count |
|---|---|----|-------|
| A | exit  | x | 1 |
| B | east  | C | 2 |
| C | east  | A | 1 |
| C | east  | D | 3 |
| D | exit  | x | 3 |
| E | north | C | 2 |

回想 \(T(s, a, s') = P(s' \mid s, a)\)，我们可以用这些计数来估计转移函数 \(\hat{T}\)，方法是将每个三元组 \((s, a, s')\) 的计数除以在 Q-状态 `(s, a)` 的总计数；奖励函数直接从探索过程中获得的奖励中获取。

### 转移函数 \(\hat{T}(s, a, s')\)

\[
\begin{aligned}
\hat{T}(A, exit, x) &= \frac{\#(A, exit, x)}{\#(A, exit)} = \frac{1}{1} = 1 \\
\hat{T}(B, east, C) &= \frac{\#(B, east, C)}{\#(B, east)} = \frac{2}{2} = 1 \\
\hat{T}(C, east, A) &= \frac{\#(C, east, A)}{\#(C, east)} = \frac{1}{4} = 0.25 \\
\hat{T}(C, east, D) &= \frac{\#(C, east, D)}{\#(C, east)} = \frac{3}{4} = 0.75 \\
\hat{T}(D, exit, x) &= \frac{\#(D, exit, x)}{\#(D, exit)} = \frac{3}{3} = 1 \\
\hat{T}(E, north, C) &= \frac{\#(E, north, C)}{\#(E, north)} = \frac{2}{2} = 1
\end{aligned}
\]

### 奖励函数 \(\hat{R}(s, a, s')\)

\[
\begin{aligned}
\hat{R}(A, exit, x) &= -10 \\
\hat{R}(B, east, C) &= -1 \\
\hat{R}(C, east, A) &= -1 \\
\hat{R}(C, east, D) &= -1 \\
\hat{R}(D, exit, x) &= +10 \\
\hat{R}(E, north, C) &= -1
\end{aligned}
\]

根据大数定律，随着智能体经历更多回合并收集更多样本，我们对 \(\hat{T}\) 和 \(\hat{R}\) 的模型会逐渐完善，\(\hat{T}\) 会收敛到真实转移函数 \(T\)，\(\hat{R}\) 会随着新的三元组 \((s, a, s')\) 的发现而获取之前未知的奖励信息。  

在适当的时候，我们可以结束智能体的训练，使用当前的 \(\hat{T}\) 和 \(\hat{R}\) 通过值迭代或策略迭代生成策略 \(\pi_{\text{exploit}}\)，并让智能体执行 MDP，采取动作以**最大化奖励**而不是继续学习。

基于模型的学习非常直观和有效，仅需计数和归一化就可以生成 \(\hat{T}\) 和 \(\hat{R}\)。然而，维护每个三元组 \((s, a, s')\) 的计数可能非常耗费内存。因此，在下一节关于无模型学习（model-free learning）中，我们将介绍绕过计数的方法，从而避免基于模型学习所需的内存开销。
