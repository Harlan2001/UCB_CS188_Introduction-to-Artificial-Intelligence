### 7.2 决策网络（Decision Networks）

之前我们学习了游戏树以及 **minimax** 和 **expectimax** 算法，用于确定最大化期望效用的最优动作。随后在第五章中，我们讨论了贝叶斯网（Bayes’ nets）及如何利用已知证据进行概率推断来做预测。现在，我们将介绍 **决策网络（Decision Network）**，它结合了贝叶斯网和 expectimax，用于根据图形化的概率模型来模拟不同行动对效用的影响。

#### 决策网络的组成

1. **机会节点（Chance nodes）**  
   与贝叶斯网中的节点相同，每个结果都有对应概率，可通过对其所属的贝叶斯网进行推断获得。通常用椭圆表示。

2. **动作节点（Action nodes）**  
   我们完全控制的节点，表示可以选择的不同行动。通常用矩形表示。

3. **效用节点（Utility nodes）**  
   效用节点是某些动作和机会节点的子节点，根据父节点取值输出效用。通常用菱形表示。

---

#### 示例：是否带伞

假设早上上课时，你考虑是否带伞，并知道天气预报降雨概率为 30%。此时是否带伞？如果降雨概率为 80%，你的决定会改变吗？这正是决策网络适用的场景，如下建模：

![](../../image/7.%20Decision%20Network%20and%20VPIs/dn-weather.png)

**决策网络天气示例**  

目标与之前一致：选择能产生**最大期望效用（MEU）**的动作。步骤如下：

1. **实例化已知证据**，并运行推断，计算动作节点所影响的效用节点的所有机会节点父节点的后验概率。
2. **计算期望效用**  
   对每个可能动作，使用后验概率计算其期望效用：
   \[
   EU(a \mid e) = \sum_{x_1, \dots, x_n} P(x_1, \dots, x_n \mid e) \, U(a, x_1, \dots, x_n)
   \]
   其中每个 \(x_i\) 表示第 \(i\) 个机会节点的可能取值，权重为各结果概率。
3. **选择期望效用最大的动作**，即得到 MEU。

---

#### 示例计算

![](../../image/7.%20Decision%20Network%20and%20VPIs/dn-with-table.png)

使用给定的条件概率表 \(P(\text{Weather} \mid F = \text{bad})\) 和效用表 \(U(\text{action, weather})\)：

\[
\begin{align*}
EU(\text{leave} \mid \text{bad}) &= 0.34 \cdot 100 + 0.66 \cdot 0 = 34 \\
EU(\text{take} \mid \text{bad}) &= 0.34 \cdot 20 + 0.66 \cdot 70 = 53
\end{align*}
\]

取最大期望效用：

\[
MEU(F = \text{bad}) = \max_a EU(a \mid \text{bad}) = 53
\]

最优动作为 **take**（带伞）。

更正式地，MEU 对应的动作可通过对期望效用取 **argmax** 得到。

---

### 7.2.1 结果树（Outcome Trees）

决策网络包含 expectimax 元素。我们可以将动作选择过程展开为**结果树**：

![](../../image/7.%20Decision%20Network%20and%20VPIs/outcome-tree.png)

- 树根为最大化节点（maximizer node），由我们控制，选择动作。
- 下一层为机会节点（chance nodes），由概率决定结果。
- 最终层为效用节点（utility nodes），输出效用，概率由贝叶斯网推断得到。

与传统 expectimax 的主要区别是：**结果树的节点会标注当前已知信息**（如花括号内的证据），便于决策。
