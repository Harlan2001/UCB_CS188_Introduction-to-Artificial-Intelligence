## 6.7 贝叶斯网中的近似推断：采样

另一种概率推断方法是通过采样隐式计算查询概率。这不会像枚举推断（IBE）或变量消去法那样精确，但在计算开销大幅降低的情况下，近似推断通常已经足够。

例如，假设我们想计算：

\[
P(+t \mid +e)
\]

如果我们有一台“魔法机器”能够从分布中生成样本，我们可以收集所有 \(E = +e\) 的样本，然后计算其中 \(T = +t\) 的比例。通过观察样本，我们就能轻松得到任意推断结果。

---

### 6.7.1 先验采样（Prior Sampling）

给定一个贝叶斯网模型，我们可以轻松写出模拟器。例如，对于仅包含两个变量 \(T\) 和 \(C\) 的简化模型：

![](../../image/6.BayesNets/TC_model.png)

**TC Model**

简单的 Python 模拟器如下：

```python
import random

def get_t():
    if random.random() < 0.99:
        return True
    return False

def get_c(t):
    if t and random.random() < 0.95:
        return True
    return False

def get_sample():
    t = get_t()
    c = get_c(t)
    return [t, c]
```
我们称这种简单方法为 **先验采样（Prior Sampling）**。这种方法的缺点是，为了分析低概率事件，可能需要生成非常大量的样本。例如，如果我们想计算 \(P(C \mid -t)\)，则必须丢弃 99% 的样本。

---

### 6.7.2 拒绝采样（Rejection Sampling）

为缓解上述问题，可以修改程序，提前拒绝与证据不一致的样本。例如，对于查询 \(P(C \mid -t)\)，只有当 \(t\) 为假时才生成 \(C\) 的值。这仍然意味着大部分样本会被丢弃，但生成无效样本所花费的时间更少。我们称这种方法为 **拒绝采样（Rejection Sampling）**。

这两种方法的原理相同：任何有效样本出现的概率都与联合概率分布（joint PDF）中指定的概率一致。

---

### 6.7.3 似然加权（Likelihood Weighting）

更高级的方法是 **似然加权**，它确保我们不会生成无效样本。在此方法中，我们手动将所有变量设置为查询中的证据值。例如，若计算 \(P(C \mid -t)\)，则直接将 \(t = false\)。

问题是，这样可能导致生成的样本与真实分布不一致。如果仅将某些变量强制设为证据值，那么样本的概率仅等于非证据变量 CPT 的乘积，因此联合概率分布不一定正确（但在如两变量贝叶斯网的情况可能成立）。

**解决方法**：为每个样本 \(j\) 赋予权重 \(w_j\)，反映给定采样变量时证据变量出现的可能性。具体做法：

- 对于查询 \(P(T \mid +c, +e)\)，第 \(j\) 个样本执行：
  1. 初始化 \(w_j = 1.0\)，并设置 \(c = true\)，\(e = true\)。
  2. 对 \(T\)：非证据变量，从 \(P(T)\) 采样 \(t_j\)。
  3. 对 \(C\)：证据变量，更新权重 \(w_j = w_j \cdot P(+c \mid t_j)\)。
  4. 对 \(S\)：从 \(P(S \mid t_j)\) 采样 \(s_j\)。
  5. 对 \(E\)：证据变量，更新权重 \(w_j = w_j \cdot P(+e \mid +c, s_j)\)。

- 最终统计时，每个样本按 \(w_j\) 权重计数，而非按 1 计数。

这样可以保证每个 CPT 都参与计算，使加权样本概率为：

\[
P(z_1 \dots z_p, e_1 \dots e_m) = \left[\prod_{i=1}^{p} P(z_i \mid Parents(z_i))\right] \cdot \left[\prod_{i=1}^{m} P(e_i \mid Parents(e_i))\right]
\]

---

![](../../image/6.BayesNets/LikelihoodWeighting.png)

对于 **先验采样、拒绝采样、似然加权** 三种方法，生成更多样本可以提高精度。但三者中 **似然加权** 最为高效，原因超出本课程范围。

---

### 6.7.4 Gibbs 采样（Gibbs Sampling）

Gibbs 采样的做法：

1. 将所有变量随机初始化（不考虑 CPT）。
2. 反复选择一个变量：
   - 清除该变量的当前值。
   - 根据其他变量当前值，从条件分布重新采样该变量。

例如 \(T, C, S, E\) 模型：

- 初始赋值：\(t=true, c=true, s=false, e=true\)
- 随机选择一个变量，如 \(S\)，清除并从条件分布 \(P(S \mid +t, +c, +e)\) 采样。

> 关键：某变量的条件分布仅依赖其邻居的 CPT。在典型贝叶斯网中，大多数变量的邻居数量很少，因此可以线性时间预计算每个变量给定邻居的条件分布。

经过足够迭代，样本会收敛到正确的分布，即使初始值概率很低。

![](../../image/6.BayesNets/Gibbs.png)

**Gibbs Sampling 伪代码**
