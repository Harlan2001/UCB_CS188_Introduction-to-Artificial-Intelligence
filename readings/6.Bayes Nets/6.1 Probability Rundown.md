# 6.1 概率概览

我们假设你已经在 **CS70** 中学习了概率的基础，因此这些笔记将假设你对概率中的标准概念有基本理解，比如概率密度函数（PDF）、条件概率、独立性以及条件独立性。这里我们提供一个我们将要使用的概率规则的简要总结。

随机变量表示一个结果未知的事件。概率分布是对结果分配权重。概率分布必须满足以下条件：

\[
0 \le P(\omega) \le 1, \quad \sum_{\omega} P(\omega) = 1
\]

例如，如果 \(A\) 是一个二元变量（只能取两个值），那么

\[
P(A=0) = p \quad \text{且} \quad P(A=1) = 1 - p
\]

其中 \(p \in [0,1]\)。

我们使用的惯例是：大写字母表示随机变量，小写字母表示该随机变量的某个具体取值。

我们用符号 \(P(A,B,C)\) 表示变量 \(A, B, C\) 的联合分布。在联合分布中，顺序不重要，即

\[
P(A,B,C) = P(C,B,A)。
\]

我们可以使用链式法则（有时也称为乘积法则）展开联合分布：

\[
P(A,B) = P(A|B)P(B) = P(B|A)P(A)
\]

\[
P(A_1, A_2, \dots, A_k) = P(A_1) P(A_2|A_1) \dots P(A_k | A_1, \dots, A_{k-1})
\]

变量 \(A, B\) 的边缘分布可以通过对变量 \(C\) 的所有可能取值求和得到：

\[
P(A,B) = \sum_c P(A,B,C=c)
\]

变量 \(A\) 的边缘分布也可以通过对 \(B\) 和 \(C\) 的所有可能取值求和得到：

\[
P(A) = \sum_b \sum_c P(A, B=b, C=c)
\]

我们有时也会把这个求边缘分布的过程称为“求和消元（summing out）”。

当我们对概率分布进行操作时，有时会得到不一定和为 1 的分布。为了解决这个问题，我们进行归一化：将分布中所有条目的和求出，然后将每个条目除以这个和。

---

条件概率是指在已知某些事实的情况下，给事件分配概率。例如，

\[
P(A | B=b)
\]

表示在已知 \(B\) 的取值为 \(b\) 的情况下 \(A\) 的概率分布。条件概率定义为：

\[
P(A|B) = \frac{P(A,B)}{P(B)}
\]

结合上述条件概率定义和链式法则，我们得到贝叶斯公式：

\[
P(A|B) = \frac{P(B|A) P(A)}{P(B)}
\]

要表示随机变量 \(A\) 和 \(B\) 互相独立，我们写作

\[
A \perp\!\!\!\perp B
\]

这等价于

\[
B \perp\!\!\!\perp A
\]

---

当 \(A\) 和 \(B\) 互相独立时，

\[
P(A,B) = P(A) P(B)
\]

一个例子是两个独立的抛硬币事件。在其他课程中，你可能会把互相独立称作“独立”。根据上述等式和链式法则，我们可以推导出：

\[
P(A|B) = P(A), \quad P(B|A) = P(B)
\]

---

要表示随机变量 \(A\) 和 \(B\) 在给定另一个随机变量 \(C\) 的条件下条件独立，我们写作：

\[
A \perp\!\!\!\perp B \mid C
\]

这也等价于

\[
B \perp\!\!\!\perp A \mid C
\]

---

如果 \(A\) 和 \(B\) 在给定 \(C\) 的条件下条件独立，那么：

\[
P(A,B|C) = P(A|C) P(B|C)
\]

这意味着，如果我们知道 \(C\) 的取值，那么 \(A\) 和 \(B\) 不会互相影响。与条件独立等价的关系还有：

\[
P(A|B,C) = P(A|C), \quad P(B|A,C) = P(B|C)
\]

注意，这三条等式等价于互相独立的三条公式，只是增加了对 \(C\) 的条件！
