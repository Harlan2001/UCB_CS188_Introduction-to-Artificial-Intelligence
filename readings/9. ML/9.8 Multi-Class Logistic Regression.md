# 9.8 多类别逻辑回归（Multi-Class Logistic Regression）

在多类别逻辑回归中，我们希望将数据点分类到 \(K\) 个不同的类别，而不仅仅是两个类别。因此，我们希望构建一个模型，为新数据点属于每个可能的 \(K\) 个类别的概率进行估计。为此，我们使用 softmax 函数代替逻辑函数，模型新数据点特征 \(x\) 属于类别 \(i\) 的概率如下：

\[
P(y = i \mid f(x); w) = \frac{e^{w_i^T f(x)}}{\sum_{k=1}^K e^{w_k^T f(x)}}
\]

注意，这些概率估计的总和为 1，因此它们构成了一个有效的概率分布。我们通过最大化观测到的数据的似然来估计参数 \(w\)。假设我们观测到 \(n\) 个带标签的数据点 \((x_i, y_i)\)。似然函数（定义为样本的联合概率分布）记作 \(\ell(w_1, \dots, w_K)\)：

\[
\ell(w_1, \dots, w_K) = \prod_{i=1}^n P(y_i \mid f(x_i); w)
\]

为了计算最大化似然的参数 \(w_i\)，我们对似然函数关于每个参数求梯度，令其等于零，并解未知参数。如果闭式解不可行，我们可以计算似然函数的梯度，并使用梯度上升法获得最优值。

一个常用技巧是先对似然函数取对数，这样可以将乘积转换为求和，并简化梯度计算。因为对数是严格递增函数，这种变换不会改变最大化点。

---

对于似然函数，我们需要一种方式来表示概率 \(P(y_i \mid f(x_i); w)\)，其中 \(y \in \{1, \dots, K\}\)。因此，对于每个数据点 \(i\)，定义 \(K\) 个参数 \(t_{i,k}\)，\(k=1, \dots, K\)，使得：

\[
t_{i,k} =
\begin{cases}
1 & \text{如果 } y_i = k \\
0 & \text{否则}
\end{cases}
\]

因此，我们可以将似然函数表达为：

\[
\ell(w_1, \dots, w_K) = \prod_{i=1}^n \prod_{k=1}^K \left( \frac{e^{w_k^T f(x_i)}}{\sum_{\ell=1}^K e^{w_\ell^T f(x_i)}} \right)^{t_{i,k}}
\]

对数似然函数为：

\[
\log \ell(w_1, \dots, w_K) = \sum_{i=1}^n \sum_{k=1}^K t_{i,k} \log \frac{e^{w_k^T f(x_i)}}{\sum_{\ell=1}^K e^{w_\ell^T f(x_i)}}
\]

---

有了目标函数的表达式后，我们必须估计 \(w_i\) 以最大化该目标。

在多类别逻辑回归的例子中，对 \(w_j\) 的梯度为：

\[
\begin{aligned}
\nabla_{w_j} \log \ell(w) &= \sum_{i=1}^n \nabla_{w_j} \sum_{k=1}^K t_{i,k} \log \frac{e^{w_k^T f(x_i)}}{\sum_{\ell=1}^K e^{w_\ell^T f(x_i)}} \\
&= \sum_{i=1}^n \left( t_{i,j} - \frac{e^{w_j^T f(x_i)}}{\sum_{\ell=1}^K e^{w_\ell^T f(x_i)}} \right) f(x_i)
\end{aligned}
\]

其中我们使用了 \(\sum_k t_{i,k} = 1\) 的事实。
