# 9.7 逻辑回归（Logistic Regression）

让我们回想一下之前的线性回归方法。在其中，我们假设输出是一个数值型实数。

如果我们想预测的是一个类别变量呢？逻辑回归允许我们使用逻辑函数将输入特征的线性组合转换为概率：

\[
h_w(x) = \frac{1}{1 + e^{-w^T x}}
\]

需要注意的是，虽然逻辑回归被称作“回归”，但这其实是一个误称。逻辑回归用于解决分类问题，而不是回归问题。

逻辑函数

\[
g(z) = \frac{1}{1 + e^{-z}}
\]

常用于建模二元输出。注意，该函数的输出始终在 0 和 1 之间，如下图所示：

![](../../image/9.%20ML/Generalized_logistic_function_A0_K1_B1.5_Q0.5_ν0.5_M0.5.png)


直观上，逻辑函数建模了数据点属于标签为 1 的类别的概率。原因是逻辑函数的输出被限制在 0 和 1 之间，而我们希望模型捕捉特征属于特定标签的概率。例如，在训练完逻辑回归后，我们对一个新数据点计算逻辑函数的输出。如果输出值大于 0.5，我们将其分类为标签 1；否则分类为标签 0。更具体地，我们建模概率如下：

\[
P(y = +1 \mid f(x); w) = \frac{1}{1 + e^{-w^T f(x)}}
\]

\[
P(y = -1 \mid f(x); w) = 1 - \frac{1}{1 + e^{-w^T f(x)}}
\]

其中，我们用 \(f(x)\) 表示特征向量 \(x\) 的函数（通常是恒等函数），分号 `;` 表示概率是参数权重 \(w\) 的函数。

---

一个有用的性质是逻辑函数的导数：

\[
g'(z) = g(z)(1 - g(z))
\]

---

### 逻辑回归的训练

逻辑回归的损失函数是 \(L_2\) 损失：

\[
\text{Loss}(w) = \frac{1}{2} (y - h_w(x))^2
\]

由于逻辑回归无法求闭式解，我们通过梯度下降来估计未知权重 \(w\)。为此，我们需要使用链式法则计算损失函数的梯度。损失函数对第 \(i\) 个坐标权重的梯度为：

\[
\frac{\partial}{\partial w_i} \frac{1}{2} (y - h_w(x))^2 = -(y - h_w(x)) \, h_w(x) \, (1 - h_w(x)) \, x_i
\]

这里我们使用了逻辑函数 \(g(z) = \frac{1}{1 + e^{-z}}\) 的梯度性质：

\[
g'(z) = g(z)(1 - g(z))
\]

然后，我们可以使用梯度下降来估计权重，并按照上述方法进行预测。
