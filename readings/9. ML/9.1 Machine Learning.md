# 9.1 机器学习

在本课程前几节笔记中，我们已经学习了各种帮助我们在不确定性下进行推理的模型类型。到目前为止，我们假设所使用的概率模型是理所当然的，而生成我们所使用的底层概率表的方法则被抽象化了。在接下来的机器学习讨论中，我们将开始打破这种抽象障碍。机器学习是计算机科学的一个广泛领域，它处理在给定数据的情况下构建和/或学习指定模型参数的问题。

机器学习算法有很多，针对不同类型的问题和数据类型，可以根据它们希望完成的任务和所处理的数据类型进行分类。机器学习算法的两个主要子类是监督学习算法和无监督学习算法。监督学习算法通过推断输入数据与对应输出数据之间的关系，以便预测新输入数据（以前未见过的）的输出。而无监督学习算法的输入数据没有对应的输出数据，因此需要识别数据点之间或数据点内部的固有结构，并据此进行分组和/或处理。在本课程中，我们讨论的算法将仅限于监督学习任务。

![Image 1](../../image/9.%20ML/train.png)  
(a) 训练  

![Image 2](../../image/9.%20ML/validation.png)  
(b) 验证  

![Image 3](../../image/9.%20ML/validation.png)  
(c) 测试  

一旦你有了可以用于学习的数据集，机器学习过程通常涉及将数据集拆分为三个不同的子集。首先，训练数据用于实际生成将输入映射到输出的模型。然后，验证数据（也称为保留数据或开发数据）用于通过对输入进行预测并生成准确率评分来衡量模型性能。如果你的模型表现不如预期，可以随时回去重新训练，通过调整称为超参数的特定模型值，或者完全使用不同的学习算法，直到你对结果满意为止。最后，使用模型对第三个也是最后一个数据子集——测试集进行预测。测试集是你的代理在开发结束之前从未见过的数据部分，相当于“期末考试”，用于评估模型在真实数据上的表现。

接下来，我们将介绍一些基础的机器学习算法，例如朴素贝叶斯（Naive Bayes）、线性回归（Linear Regression）、逻辑回归（Logistic Regression）和感知机算法（Perceptron algorithm）。
