## 3.5 蒙特卡罗树搜索（Monte Carlo Tree Search）

对于分支因子很大的应用（例如围棋），minimax 已无法使用。在这种情况下，我们使用 **蒙特卡罗树搜索（MCTS）** 算法。MCTS 基于两个思想：

- **通过随机模拟进行评估（Evaluation by rollouts）：** 从状态 \( s \) 出发，使用某种策略（例如随机策略）进行多次对局，并统计胜负次数。
- **选择性搜索（Selective search）：** 在没有固定搜索深度限制的情况下，探索那些能够提升根节点决策质量的树的部分区域。

在围棋的例子中，从某个给定状态出发，我们按照某种策略反复进行对局直到终止。记录获胜的比例，该比例与该状态的价值具有较好的相关性。

考虑如下示例：

![](../../image/3.Games/MCTS1.png)

MCTS Example 1

从当前状态出发，我们有三个可选动作（左、中、右）。我们对每个动作分别进行 \(100\) 次模拟，并记录各自动作的胜率。模拟结束后，我们相当有信心认为“右”这个动作是最好的。

在这个情境中，我们为每个候选动作分配了相同数量的模拟次数。然而，在进行少量模拟后，可能会发现某个动作几乎没有带来胜利，因此我们可以选择把原本分配给它的计算资源用于对其他动作进行更多模拟。如下图所示，我们将原本分配给“中间”动作的剩余 \(90\) 次模拟分配给了“左”和“右”。

![](../../image/3.Games/MCTS2.png)

MCTS Example 2

另一种有趣的情况是：某些动作的胜率相近，但其中一个动作用于估计该胜率的模拟次数远少于其他动作，如下图所示。在这种情况下，模拟次数较少的那个动作，其估计值的方差更高，因此我们可能希望为该动作分配更多模拟次数，以更有信心地估计其真实胜率。

![](../../image/3.Games/MCTS3.png)

MCTS Example 3

UCB 算法通过在每个节点 \( n \) 使用以下准则，来刻画“有前景”与“不确定性”之间的权衡：

\[
UCB1(n) =
\frac{U(n)}{N(n)}
+
C \times
\sqrt{
\frac{
\log N(PARENT(n))
}{
N(n)
}
}
\]

其中：

- \( N(n) \) 表示从节点 \( n \) 出发的总模拟次数
- \( U(n) \) 表示对于 \( Player(Parent(n)) \) 来说的总胜利次数

第一项反映该节点的“有前景程度”，第二项反映我们对该节点效用的不确定程度。用户指定的参数 \( C \) 用于平衡这两部分（“探索”与“利用”），具体取值取决于应用场景，以及任务所处阶段（在后期，当我们已经积累了大量模拟时，通常会减少探索，增加利用）。

MCTS 中的 UCT 算法在树搜索问题中使用 UCB 准则。更具体地说，它会重复以下三个步骤多次：

1. 使用 UCB 准则，从根节点向下在树中选择路径，直到到达一个尚未扩展的叶节点。
2. 在该叶节点处添加一个新的子节点，并从该子节点开始进行一次模拟，以确定该节点的胜利次数。
3. 将该子节点的胜利次数沿路径向上回传并更新至根节点。

当上述三个步骤重复足够多次之后，我们选择那个通向拥有最高 \( N \) 值子节点的动作。需要注意的是，由于 UCT 会对更有前景的子节点进行更多次探索，当 \( N \to \infty \) 时，UCT 的行为将趋近于 minimax 智能体的行为。
