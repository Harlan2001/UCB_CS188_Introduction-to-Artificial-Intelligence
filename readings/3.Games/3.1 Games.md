## 3.1 博弈

在第一讲中，我们讨论了搜索问题以及如何高效且最优地解决它们——通过强大的通用搜索算法，我们的智能体可以确定最佳可能的计划，然后只需执行它即可到达目标。现在，让我们转换一下思路，考虑这样一种情境：我们的智能体面临一个或多个对手，这些对手试图阻止它们实现目标。我们的智能体无法再运行我们已经学习过的搜索算法来制定计划，因为我们通常无法确定性地知道对手会如何针对我们进行规划以及如何对我们的行动作出回应。相反，我们需要运行一类新的算法来求解对抗性搜索问题，这类问题更常被称为博弈。

博弈有许多不同类型。博弈中的行动可能具有确定性结果，也可能具有随机（概率性）结果；参与者数量可以是任意的；并且博弈可能是零和，也可能不是零和。我们将首先讨论确定性零和博弈，在这类博弈中，行动结果是确定性的，并且我们的收益恰好等同于对手的损失，反之亦然。理解这类博弈最简单的方式，是将其视为由一个单一变量值所定义：一方或一个智能体试图最大化该变量，而对立的一方或智能体试图最小化该变量，从而使双方形成直接竞争关系。在吃豆人（Pacman）中，这个变量就是你的得分，你通过快速且高效地吃豆子来最大化得分，而幽灵则通过先吃掉你来最小化你的得分。许多常见的家庭游戏也属于这一类：

- **跳棋（Checkers）** —— 第一位跳棋计算机玩家创建于 1950 年。此后，跳棋成为一个已解决的博弈，这意味着在双方都采取最优策略的前提下，任何局面都可以被确定性地评估为某一方的胜、负或和局。  
- **国际象棋（Chess）** —— 1997 年，Deep Blue 成为第一个在六局比赛中击败人类国际象棋冠军 Garry Kasparov 的计算机智能体。Deep Blue 被构建为能够使用极其复杂的方法每秒评估超过 2 亿个局面。当前的程序更强，但历史意义不如当年那般重大。  
- **围棋（Go）** —— 围棋的搜索空间远大于国际象棋，长期以来大多数人认为围棋计算机智能体在未来若干年内都不可能击败人类世界冠军。然而，由 Google 开发的 AlphaGo 在 2016 年 3 月以 4 比 1 的成绩历史性地击败了围棋冠军李世石。

![](../../image/3.Games/common-games.png)

### 常见博弈

上述所有世界冠军级别的智能体，在某种程度上都使用了我们即将讨论的对抗性搜索技术。与普通搜索返回一个完整计划不同，对抗性搜索返回的是一种策略（strategy）或策略函数（policy），它仅仅在给定某种智能体及其对手的配置时，推荐当前最优的行动。我们很快将看到，这类算法具有一个优美的性质：通过计算产生行为——我们运行的计算在概念上相对简单且具有广泛的通用性，却天然地在同一队伍的智能体之间产生协作，同时也实现了对对抗性智能体的“智胜”。

标准的博弈形式化包括以下定义：

- 初始状态，  
  \( s_0 \)

- 玩家，  
  \( Players(s) \) 表示当前轮到谁行动

- 行动，  
  \( Actions(s) \) 表示该玩家可采取的行动

- 转移模型，  
  \( Result(s, a) \)

- 终止测试，  
  \( Terminal\text{-}test(s) \)

- 终止值，  
  \( Utility(s, player) \)
