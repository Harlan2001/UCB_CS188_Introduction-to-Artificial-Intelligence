# 1.4 有信息搜索（Informed Search）

一致代价搜索（Uniform Cost Search, UCS）之所以优秀，是因为它**既是完备的（complete），又是最优的（optimal）**。但它也可能相当缓慢，因为它在搜索目标的过程中会从起始状态向**所有方向**进行扩展。如果我们对“搜索应当朝哪个方向集中”有一定的先验认知，就可以显著提升性能，更快地“锁定”目标。这正是**有信息搜索（informed search）** 所关注的核心问题。

---

## 1.4.1 启发式函数（Heuristics）

启发式函数是实现“估计到目标状态距离”的核心驱动力——它们是**以状态作为输入，并输出一个对应估计值的函数**。该函数所进行的计算是**特定于具体搜索问题**的。

- 在搜索过程中，大多数时候“无法在不知道答案的前提下，准确算出到目标的真实距离”；如果能准确算出来，搜索本身就没有存在的必要了。精确距离 = 需要完整搜索；而启发式的目的正是避免完整搜索

基于我们稍后在 A\* 搜索中将会看到的原因，我们通常希望启发式函数给出的估计值是**到目标的剩余距离的下界**。因此，启发式函数通常来源于**放宽约束后的问题（relaxed problems）** 的解，也就是说，原问题中的某些约束被移除了。

回到我们之前提到的 Pacman 示例，考虑路径规划问题。一个常用的启发式函数是**曼哈顿距离（Manhattan distance）**。对于两点 $(x_1, y_1)$ 和 $(x_2, y_2)$，其定义如下：

$$
\text{Manhattan}(x_1, y_1, x_2, y_2) = |x_1 - x_2| + |y_1 - y_2|
$$

![](../../image/1.search/manhattan.png)

**曼哈顿距离的可视化说明**

上面的可视化展示了曼哈顿距离所对应的放宽问题：假设 Pacman 想要到达迷宫的左下角，该距离是在**假设迷宫中不存在墙壁**的前提下，从 Pacman 当前所在位置到目标位置的距离。

这个距离在放宽后的搜索问题中，正是**真实的目标距离**；而在原始搜索问题中，它就成为了**对目标距离的估计值**。

借助启发式函数，我们可以非常容易地在智能体中实现一种逻辑：在决定执行哪个动作时，**优先扩展那些被估计为更接近目标状态的节点**。这种“偏好”的概念非常强大，下面介绍的两种搜索算法正是利用启发式函数实现这一思想的：**贪心搜索（Greedy Search）**和 **A\*** 搜索。

---

## 1.4.2 贪心搜索（Greedy Search）

**描述（Description）**  
贪心搜索是一种探索策略，它**总是选择启发式值最低的前沿节点进行扩展**，也就是说，它选择自己“认为”距离目标最近的状态。

**前沿表示（Frontier Representation）**  
贪心搜索在前沿（frontier）的表示方式上与 UCS 完全相同，使用的是**优先队列（priority queue）**。不同之处在于：

- UCS 使用的是**向后的累计代价**（即到当前状态路径上所有边权的和）来决定优先级；
- 贪心搜索使用的是**向前的估计代价**，即启发式函数的值。

**完备性与最优性（Completeness and Optimality）**  
贪心搜索**不保证在目标存在时一定能找到目标状态**，也**不保证最优性**，尤其是在选择了一个非常糟糕的启发式函数时。  
它在不同场景下的行为通常非常不可预测：

- 有时会直接冲向目标状态；
- 有时却像一个被严重误导的 DFS 一样，在完全错误的区域中进行探索。

> 贪心搜索在“好日子”的表现 :)

![](../../image/1.search/good_greedy.png)

> 贪心搜索在“坏日子”的表现 :(

![](../../image/1.search/bad_greedy.png)

---

## 1.4.3 A\* 搜索（A\* Search）

**描述（Description）**  
A\* 搜索是一种探索策略，它**总是选择估计“总代价”最低的前沿节点进行扩展**。这里的总代价指的是：从起始节点到目标节点的**整个路径代价**。

**前沿表示（Frontier Representation）**  
与贪心搜索和 UCS 一样，A\* 搜索同样使用**优先队列**来表示前沿。唯一的区别仍然在于优先级的计算方式。

A\* 将：

- UCS 使用的**向后累计代价**（路径上边权之和），
- 与贪心搜索使用的**向前估计代价**（启发式值），

二者**相加**，从而得到从起点到目标的**估计总代价**。  
由于我们的目标正是最小化从起点到目标的总代价，这种做法是一个非常优秀的选择。

**完备性与最优性（Completeness and Optimality）**  
在选择了合适的启发式函数的前提下，A\* 搜索**既是完备的，又是最优的**。  
它综合了此前所有搜索策略的优点：

- 拥有贪心搜索通常具备的高速性；
- 同时保留了 UCS 的最优性和完备性。

---

## 1.4.4 可采纳性（Admissibility）

在讨论了启发式函数及其在贪心搜索和 A\* 搜索中的应用之后，我们接下来需要讨论：**什么样的启发式函数才算是“好的”**。

为此，我们首先重新表述 UCS、贪心搜索和 A\* 搜索中用于确定优先队列顺序的方法，并引入以下定义：

- $g(n)$：表示 UCS 计算得到的**向后累计代价函数**
- $h(n)$：表示启发式函数，即贪心搜索使用的**向前估计代价**
- $f(n)$：表示 A\* 搜索使用的**估计总代价函数**

$$
f(n) = g(n) + h(n)
$$

在探讨什么是“好”的启发式函数之前，我们必须先回答一个问题：  
**A\* 是否在任意启发式函数下都能保持完备性和最优性？**

答案是否定的。事实上，非常容易构造出会破坏这两个性质的启发式函数。例如，考虑如下启发式函数：

$$
h(n) = 1 - g(n)
$$

无论搜索问题是什么，使用该启发式函数都会得到：

$$
f(n) = g(n) + h(n) = g(n) + (1 - g(n)) = 1
$$

因此，这种启发式函数会将 A\* 搜索退化为 **BFS**，其中所有边的代价都被视为相同。而我们已经证明过，在边权不恒定的一般情况下，BFS **并不能保证最优性**。

---

### 可采纳性条件

在 **A\* 树搜索（tree search）** 中，为了保证最优性，需要满足的条件被称为**可采纳性（admissibility）**。

可采纳性约束要求：  
**启发式函数给出的估计值既不能为负，也不能高估到目标的真实代价。**

令 $h^*(n)$ 表示从节点 $n$ 到某个目标状态的**真实最优向前代价**，则可采纳性可形式化为：

$$
\forall n,\quad 0 \le h(n) \le h^*(n)
$$

**定理**  
对于给定的搜索问题，如果启发式函数 $h$ 满足可采纳性约束，那么在该搜索问题上使用启发式函数 $h$ 的 A\* 树搜索将产生一个**最优解**。

**证明**  
假设在搜索树中存在两个可达的目标状态：

- 一个最优目标 $A$，
- 一个次优目标 $B$。

由于 $A$ 从起始状态是可达的，因此 $A$ 的某个祖先节点 $n$（可能就是 $A$ 本身）当前必然位于前沿中。我们声称：**节点 $n$ 会在 $B$ 之前被扩展**，理由如下：

1. $g(A) < g(B)$

   因为 $A$ 是最优目标而 $B$ 是次优目标，所以 $A$ 到起点的向后代价必然小于 $B$。

2. $h(A) = h(B) = 0$

   由于启发式函数满足可采纳性，而 $A$ 和 $B$ 都是目标状态，因此从它们到目标的真实最优代价为

   $$
   h^*(n) = 0
   $$

   从而有

   $$
   0 \le h(n) \le 0
   $$

3. $f(n) \le f(A)$

   由可采纳性可得：

   $$
   f(n) = g(n) + h(n) \le g(n) + h^*(n) = g(A) = f(A)
   $$

将结论 1 和 2 合并，可以得到：

$$
f(A) = g(A) + h(A) = g(A) < g(B) = g(B) + h(B) = f(B)
$$

再结合结论 3，可得：

$$
f(n) \le f(A) \land f(A) < f(B) \Rightarrow f(n) < f(B)
$$

因此，节点 $n$ 会在 $B$ 之前被扩展。  
由于 $n$ 是任意选择的 $A$ 的祖先节点，我们可以得出结论：**$A$ 的所有祖先（包括 $A$ 本身）都会在 $B$ 之前被扩展**。

---

### 从树搜索到图搜索

前文提到，树搜索在某些情况下可能会陷入无限循环，永远无法找到解，即在状态空间图中的某个环上反复搜索。即便不存在无限循环，搜索算法也常常会**多次访问同一个节点**，因为可能存在多条路径通向同一状态。这会导致**指数级的额外工作量**。

自然的解决方案是：  
**记录已经扩展过的状态，并且不再对它们进行扩展。**

更具体地说：

- 维护一个名为 **reached** 的集合，用来存储已经扩展过的节点；
- 在扩展节点之前，先检查该节点是否已经在集合中；
- 若不在，则扩展并加入集合。

加入这一优化后的树搜索被称为**图搜索（graph search）**¹。

然而，要在 A\* 图搜索中维持最优性，还需要满足**另一个关键条件**。考虑如下简单的状态空间图及其对应的搜索树（已标注边权和启发式值）：

**状态空间图与搜索树**

![](../../image/1.search/bad_graph_search.png)

在该示例中，显然最优路径是：

$$
S \rightarrow A \rightarrow C \rightarrow G
$$

其总代价为 1 + 1 + 3 = 5

另一条到达目标的路径是：

$$
S \rightarrow B \rightarrow C \rightarrow G
$$

其总代价为 $1 + 2 + 3 = 6$。

然而，由于节点 $A$ 的启发式值远大于节点 $B$ 的启发式值，节点 $C$ 会首先作为 $B$ 的子节点被扩展（即沿着次优路径）。此时，$C$ 被加入 **reached** 集合。随后，当 A\* 搜索从 $A$ 扩展到 $C$ 时，由于 $C$ 已在 reached 集合中，它不会被重新扩展，从而**错失最优解**。

因此，为了在 A\* 图搜索中保持最优性，我们不仅需要检查某个节点是否已经被访问过，还必须检查：**是否已经找到了到该节点的一条更便宜的路径**。

---

### A\* 图搜索伪代码

```python
function A*-GRAPH-SEARCH(problem, frontier) return a solution or failure
reached ← 一个从节点到其代价的空字典
frontier ← INSERT((MAKE-NODE(INITIAL-STATE[problem]), 0), frontier)
   while frontier 非空 do
   node, node.CostToNode ← POP(frontier)
   if problem.IS-GOAL(node.STATE) then return node
   if node.STATE 不在 reached 中
   or reached[node.STATE] > node.CostToNode then
      reached[node.STATE] = node.CostToNode
      for each child-node in EXPAND(problem, node) do
         frontier ← INSERT((child-node,child-node.COST + CostToNode), frontier)
return failure
```

需要注意的是，在实际实现中，**必须将 reached 集合存储为不相交集合（如哈希表）而不是列表**。如果使用列表，检查成员关系将需要 $O(n)$ 的时间复杂度，从而完全抵消图搜索所带来的性能提升。

在继续之前，总结几个重要结论：

- 对于可采纳的启发式函数，必须满足：  
  \[
  h(G) = 0
  \]
  对任意目标状态 $G$。

---

## 1.4.5 支配性（Dominance）

在明确了可采纳性及其在 A\* 搜索最优性中的作用后，我们回到最初的问题：**如何构造“好的”启发式函数，以及如何判断一个启发式函数是否优于另一个**。

衡量标准被称为**支配性（dominance）**。如果启发式函数 $a$ 支配启发式函数 $b$，那么对于状态空间图中的每一个节点，$a$ 给出的目标距离估计都不小于 $b$ 给出的估计：

$$
\forall n:\quad h_*(n)(真实值) \ge h_a(n) \ge h_b(n)
$$

支配性非常直观地刻画了“哪个启发式函数更好”：  
如果一个可采纳的启发式函数支配另一个，那么它一定更优，因为它在任何状态下都能**更接近真实的目标距离**。

**平凡启发式函数（trivial heuristic）** 定义为：

$$
h(n) = 0
$$

使用该启发式函数会使 A\* 搜索退化为 UCS。所有可采纳的启发式函数都支配平凡启发式函数。对于一个搜索问题，平凡启发式函数通常位于一个**半格（semi-lattice）结构的底部**，该结构表示启发式函数之间的支配层级关系。

下面是一个示例半格，其中包含多个启发式函数 $h_a$、$h_b$、$h_c$，从底部的平凡启发式函数一直到顶部的精确目标距离：

**半格示例**

![](../../image/1.search/semi-lattice.png)

一般而言，对多个可采纳启发式函数取 **max** 运算，其结果仍然是可采纳的。这是因为对于任意状态 $n$，所有启发式函数的输出都满足：

$$
0 \le h(n) \le h^*(n)
$$

处于该区间内的数的最大值，必然仍然处于该区间中。因此，在实践中，常见的做法是：

- 为同一个搜索问题设计多个可采纳启发式函数；
- 对它们的输出取最大值；
- 从而得到一个**支配所有单独启发式函数的、更优的启发式函数**。

---

在其他课程中（如 CS70 和 CS170），你可能在图论语境下接触过“树”和“图”的概念，其中树是一类满足特定约束（连通且无环）的图。本课程中所说的“树搜索”和“图搜索”**并不是这种图论意义上的区分**。
