# 1.5 局部搜索（Local Search）

在前面的内容中，我们的目标是**找到目标状态，并同时找到一条到达该目标的最优路径**。然而，在某些问题中，我们只关心找到目标状态本身——至于路径如何构造，往往是显而易见或无关紧要的。

例如，在 **数独（Sudoku）** 问题中，最终的合法填表配置就是目标。一旦你知道了这个配置，就自然知道是如何一步一步填入数字得到它的。

**局部搜索算法（local search algorithms）**允许我们在**不关心到达路径的情况下直接寻找目标状态**。在局部搜索问题中，状态空间由一组“**完整解（complete solutions）**”构成。我们使用这些算法来寻找一个满足某些约束条件的配置，或者使某个目标函数达到最优（最大化或最小化）。

---

### 目标函数示意图（Objective Function Plot）

![](../../image/1.search/maxima_global_local.png)

上图展示了一个目标函数在状态空间中的一维示意。对于该函数，我们希望找到对应于**目标函数值最高**的状态。

局部搜索算法的基本思想是：  
从任意一个状态出发，**在局部范围内不断向目标函数值更高的状态移动**，直到到达一个最大值（理想情况下是全局最大值）。

我们将介绍四种局部搜索算法：

- 爬山法（hill-climbing）
- 模拟退火（simulated annealing）
- 局部束搜索（local beam search）
- 遗传算法（genetic algorithms）

这些算法同样广泛用于优化任务中，用于**最大化或最小化某个目标函数**。

---

## 1.5.1 爬山搜索（Hill-Climbing Search）

爬山搜索算法（也称为**最陡上升法，steepest-ascent**）从当前状态出发，**移动到能够最大程度提升目标函数值的相邻状态**。

该算法**不维护搜索树**，而只跟踪当前状态及其对应的目标函数值。由于爬山法具有强烈的“贪心性”，它很容易陷入以下问题（见图 4.1）：

- **局部极大值（local maxima）**：  
  在局部范围内看似是最优点，但实际上并非全局最优。
- **停滞（plateaus）**：  
  目标函数值在一片区域内保持不变。  
  平台可以进一步分为：
  - **平坦局部极大值（flat local maxima）**：没有任何方向可以继续改进；
  - **肩部（shoulders）**：虽然仍然是平坦区域，但存在可以缓慢前进的方向。

为了解决这些问题，人们提出了多种爬山法的变体。例如：

- **随机爬山（stochastic hill-climbing）**：  
  在所有能够提升目标函数值的动作中，随机选择一个。实践表明，该方法往往能以更多迭代次数为代价，收敛到更高的极值。
- **随机侧向移动（random sideways moves）**：  
  允许执行那些不会严格提升目标函数值的动作，从而帮助算法摆脱“肩部”区域。

---

### 爬山算法（Hill-Climbing Algorithm）

![](../../image/1.search/hill_climb-1.png)

上图展示了爬山算法的伪代码。顾名思义，该算法不断迭代地移动到目标函数值更高的状态，直到无法再取得任何改进。

爬山搜索是**不完备的（incomplete）**。  
而**随机重启爬山法（random-restart hill-climbing）**则从多个随机初始状态分别执行爬山搜索。由于最终有可能从某个初始状态收敛到全局最优解，因此它在理论上是**完备的**。

> 需要注意的是，在本课程后续内容中，你会遇到“**梯度下降（gradient descent）**”这一术语。  
> 它与爬山法在思想上是完全相同的，只不过：
>
> - 爬山法 **最大化目标函数**；
> - 梯度下降 **最小化代价函数**。

---

## 1.5.2 模拟退火搜索（Simulated Annealing Search）

第二种局部搜索算法是**模拟退火（simulated annealing）**。  
模拟退火试图将**随机游走（random walk）**与**爬山法**结合起来，从而得到一种既高效又完备的搜索算法。

在模拟退火中，**允许算法移动到目标函数值更低的状态**。

算法在每一个时间步都会随机选择一个移动：

- 如果该移动使目标函数值变大，则**必然接受**；
- 如果该移动使目标函数值变小，则**以一定概率接受**。

该概率由一个称为**温度（temperature）**的参数控制：

- 初始温度较高，允许较多“坏”移动；
- 温度按照某种“**退火计划（schedule）**”逐渐降低。

从理论上讲，如果温度下降得足够慢，模拟退火算法**以趋近于 1 的概率到达全局最优解**。

---

### 模拟退火算法（Simulated Annealing Algorithm）

![](../../image/1.search/sim_ann-1.png)

（见上方伪代码）

---

## 1.5.3 局部束搜索（Local Beam Search）

局部束搜索是爬山搜索的另一种变体。  
二者的关键区别在于：**局部束搜索在每一次迭代中同时维护 $k$ 个状态（称为线程）**。

算法流程如下：

- 从 $k$ 个随机初始化的状态开始；
- 在每一次迭代中，生成所有线程的后继状态；
- 从**所有这些后继状态的并集中，选出最好的 $k$ 个**作为下一轮的线程。

需要强调的是，这并不是简单地运行 $k$ 次独立的爬山算法。关键在于：  
**线程之间是共享信息的**。

如果某个线程进入了目标函数值较高的区域，它会“吸引”其他线程向该区域靠拢。

一旦任意一个线程找到了最优解，算法就会终止。

与爬山法类似，局部束搜索也可能陷入平坦区域。  
**随机束搜索（stochastic beam search）**是其对应的随机化版本，可以在一定程度上缓解这一问题。

---

## 1.5.4 遗传算法（Genetic Algorithms）

最后介绍的是**遗传算法（genetic algorithms）**。  
遗传算法是局部束搜索的一种变体，并在许多优化任务中得到了广泛应用。

正如其名称所暗示的，遗传算法的灵感来源于**生物进化**。

遗传算法可以被看作是：

- 以 $k$ 个随机初始化的状态作为起点的束搜索；
- 这些状态被称为**种群（population）**；
- 每个状态（称为**个体，individual**）用有限字母表上的一个字符串来表示。

### 8 皇后问题回顾（8-Queens Problem）

回顾课堂中介绍的 **8 皇后问题**：  
这是一个约束满足问题，目标是在一个 $8 \times 8$ 的棋盘上放置 8 个皇后，使得任意两个皇后之间都不存在攻击关系（即不在同一行、同一列或同一对角线上）。

此前介绍的所有搜索算法都可以用于求解该问题。

### 遗传算法在 8 皇后问题中的表示

![](../../image/1.search/8queen-1.jpg)

在遗传算法中，我们用一个从 $1$ 到 $8$ 的数字来表示每一列中皇后所在的行（见图 4.6 中的列 (a)）。  
因此，每个个体由一个长度为 8 的字符串表示。

![](../../image/1.search/gen2-1.png)

每个个体都会通过一个 **评价函数（evaluation function，也称适应度函数 fitness function）** 进行评估，并根据该函数值进行排序。

对于 8 皇后问题，该适应度函数就是：  
**互不攻击的皇后对数（non-attacking pairs）**。

---

### 遗传算法示例（Genetic Algorithm Example）

个体被选中用于“繁殖”的概率与其适应度值成正比。  
我们根据这些概率对个体进行采样，选择成对的个体进行繁殖（见图 4.6 中的列 (c)）。

后代通过在父代字符串的某个**交叉点（crossover point）**进行交叉生成，该交叉点对每一对父代都是随机选择的。

最后，每个后代还会以某个独立概率发生**随机变异（mutation）**。

---

### 遗传算法伪代码（Genetic Algorithm Pseudocode）

![](../../image/1.search/genetic-1.png)

（见上方伪代码）

---

与随机束搜索类似，遗传算法在探索状态空间的同时，倾向于向目标函数值更高的方向移动，并允许不同线程之间交换信息。

遗传算法的主要优势在于**交叉操作（crossover）**：  
已经进化出的、能够带来高适应度的大段“优良基因”可以与其他类似的片段组合，从而生成**整体评分更高的解**。

![](../../image/1.search/8queen-2.jpg)
