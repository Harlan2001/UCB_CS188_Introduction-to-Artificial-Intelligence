## 1.6 总结（Summary）

我们讨论了 **搜索问题（search problems）** 及其组成要素，包括：

- **状态空间（state space）**
- **动作集合（set of actions）**
- **状态转移函数（transition function）**
- **动作代价（action cost）**
- **起始状态（start state）**
- **目标状态（goal state）**

智能体（agent）通过其 **传感器（sensors）** 和 **执行器（actuators）** 与环境进行交互。  
**智能体函数（agent function）** 描述了智能体在所有可能情形下的行为。  
智能体的 **理性（rationality）** 意味着：智能体试图 **最大化其期望效用（expected utility）**。  
最后，我们使用 **PEAS 描述（Performance measure, Environment, Actuators, Sensors）** 来定义任务环境。

---

### 搜索技术回顾

针对搜索问题，我们可以使用多种搜索技术来求解，其中包括（但不限于）CS 188 课程中重点介绍的以下五种：

- **广度优先搜索（Breadth-First Search）**
- **深度优先搜索（Depth-First Search）**
- **一致代价搜索（Uniform Cost Search）**
- **贪心搜索（Greedy Search）**
- **A\* 搜索（A\* Search）**

上述前三种搜索技术属于**无信息搜索（uninformed search）**；  
后两种属于**有信息搜索（informed search）**，它们使用 **启发式函数（heuristics）** 来估计到目标的距离，从而提升搜索效率并优化性能。

此外，我们还区分了上述搜索技术中的两种实现方式：

- **树搜索（tree search）**
- **图搜索（graph search）**

---

### 局部搜索回顾

我们还讨论了 **局部搜索算法（local search algorithms）** 及其动机。当我们**不关心到达目标状态的路径**，而只希望满足某些约束条件或优化某个目标函数时，可以使用局部搜索方法。

局部搜索方法在处理**巨大状态空间**时具有显著优势：  
它们能够**节省空间**，并且往往能够找到**足够好的解（adequate solutions）**。

---

### 基础局部搜索方法

我们介绍了几种相互递进、具有代表性的局部搜索方法：

- **爬山法（Hill-Climbing）**
- **模拟退火（Simulated Annealing）**
- **局部束搜索（Local Beam Search）**
- **遗传算法（Genetic Algorithms）**

---

最后，**函数优化（optimizing a function）** 这一思想将在本课程的后续内容中反复出现，尤其是在我们学习**神经网络（neural networks）** 时，将再次成为核心主题之一。

---

# 个人补充

## 搜索算法与 AI 的关系：它们到底有什么用？

你的疑问非常关键，也是**从“学算法”过渡到“理解 AI 在干什么”**的分水岭问题。  
简短结论先给出一句话版本：

> **搜索是 AI 的“决策引擎”，而学习（如神经网络）是“经验压缩器”。**  
> 绝大多数 AI 系统，最终都在做“在巨大的可能性空间中，找到一个足够好的决策或配置”的事情，而这本质上就是搜索。

下面我们系统地解释 **这些搜索算法和 AI 的关系**，以及**它们在真实 AI 系统中的具体用途**。

---

## 一、为什么“搜索”是 AI 的核心问题？

### 1. AI 的本质：在状态空间中做决策

几乎所有 AI 问题，都可以抽象为：

- 一个**状态空间**（世界的所有可能情况）
- 一组**动作**
- 一个**目标**或**评价函数**
- 在有限时间 / 资源下，找到一个**好决策**

这和你学过的搜索问题**完全一致**。

| AI 问题    | 本质                                  |
| ---------- | ------------------------------------- |
| 下棋       | 在博弈状态空间中搜索最优策略          |
| 机器人规划 | 在物理状态空间中搜索可行动作序列      |
| 自动驾驶   | 在连续状态空间中搜索安全 / 高效决策   |
| 模型推理   | 在计算图 / 程序空间中搜索最优计算路径 |
| 优化问题   | 在参数空间中搜索最优解                |

👉 **搜索不是“AI 的一个模块”，而是 AI 的基本思维方式。**

---

## 二、无信息搜索在真实 AI 中的作用

### 1. BFS / DFS：系统性探索与验证

**应用实例：**

#### ✅ 程序分析 & 自动验证

- 状态：程序执行状态
- 动作：执行下一条指令
- BFS：寻找最短反例
- DFS：快速找到某条可行执行路径

👉 用在：

- 编译器
- 程序模型检查
- 自动 bug 查找

---

### 2. UCS：最优路径与最小代价规划

**应用实例：**

#### ✅ 机器人路径规划（基础版本）

- 状态：机器人位置
- 动作：移动
- 代价：能耗 / 时间 / 风险
- UCS：保证找到**最省成本的路径**

👉 UCS 是：

- A\* 的理论基础
- 工程系统中“兜底的最优方法”

---

## 三、有信息搜索（A\* / Greedy）在 AI 中的地位

### 1. A\*：工业级 AI 的“王牌算法”

A\* 是 **AI 历史上最成功、最实用的算法之一**。

#### ✅ 实际应用

##### 🚗 自动导航 / 地图规划

- Google Maps / 高德 / 百度
- 状态：路口
- 动作：道路
- 启发式：直线距离 / 时间估计

##### 🤖 机器人运动规划

- ROS 中大量使用 A\*
- 工厂机器人、仓储机器人

##### 🎮 游戏 AI（路径规划）

- RTS / RPG / FPS
- NPC 寻路几乎必用 A\*

👉 **你几乎每天都在用 A\***，只是你不知道。

---

### 2. 启发式 = “人类经验的编码形式”

启发式函数本质上是：

> **“我凭经验觉得往哪走比较好”**

这就是为什么：

- 启发式 = 领域知识
- 好启发式 = 强 AI 表现

---

## 四、局部搜索在现代 AI 中的真实用途

### 1. 局部搜索 = 连续优化的祖先

你在 1.5 学到的这些算法，其实就是：

| 课程名              | AI / ML 中的名字    |
| ------------------- | ------------------- |
| Hill-Climbing       | 梯度上升 / 梯度下降 |
| Simulated Annealing | 随机优化 / 非凸优化 |
| Local Beam Search   | 多启动并行优化      |
| Genetic Algorithms  | 进化计算            |

---

### 2. 梯度下降 = 爬山法（反向）

#### ✅ 神经网络训练

- 状态：参数向量 θ
- 目标函数：loss / reward
- 梯度下降：**在高维参数空间做局部搜索**

👉 **深度学习 = 超大规模连续状态空间的局部搜索**

---

### 3. 模拟退火 / 遗传算法的现实应用

#### ✅ 超参数搜索

- 学习率、层数、结构选择

#### ✅ 神经架构搜索（NAS）

- Google 使用遗传算法 + 强化学习
- 搜索“网络结构本身”

#### ✅ 工程优化

- 电路设计
- 物流调度
- 金融组合优化

---

## 五、搜索 vs 学习：AI 的两大支柱

| 搜索                  | 学习             |
| --------------------- | ---------------- |
| 显式探索可能性        | 从数据中压缩经验 |
| 保证性强（最优/完备） | 泛化能力强       |
| 推理、规划            | 感知、预测       |

### 现实中的 AI 系统通常是**混合体**

#### 例子：AlphaGo

- **神经网络**：学估值函数（启发式）
- **蒙特卡洛树搜索**：做决策搜索

👉 **没有搜索，学习无法做决策；  
没有学习，搜索效率无法接受。**

---

## 六、总结一句“工程级”理解

> **搜索算法解决的是：  
> “在巨大的可能性空间中，如何用有限计算资源做出好决策。”**

它们：

- 是 AI 推理与规划的基础
- 是深度学习优化的数学原型
- 是几乎所有智能系统的“骨架”

如果你愿意，下一步我可以：

- 用 **你熟悉的量化 / 优化问题**重写一遍搜索模型
- 或直接画一张 **“AI 技术栈：搜索在什么位置”** 的结构图
